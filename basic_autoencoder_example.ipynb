{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% load required libraies\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from skimage.transform import resize\n",
    "\n",
    "# %% this file implements different types of autoencoders\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%input%%%%%%%%%%%%%%%%%%%%%%%%%%%% \n",
    "# list of images for training\n",
    "# bool variable to check if the data is normalized or not\n",
    "# test image for autoencoder\n",
    "# dimesions of the network\n",
    "# number of iterations\n",
    "# batch size\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%output%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#  the decoded image using the autoencoder \n",
    "# Some of the codes are taken from :\n",
    "# https://github.com/pkmital/tensorflow_tutorials\n",
    "\n",
    "def basic_auto_encoder(imgs_list, test_img, normalized=False, data_dimensions=[780, 512, 256, 64], n_epochs=50, batch_size=50):\n",
    "    global img_w \n",
    "    img_w = 50\n",
    "    global img_h \n",
    "    img_h = 50\n",
    "    if normalized:\n",
    "        train_imgs_list_normalized = imgs_list\n",
    "        test_img_normalized = test_img\n",
    "    else:\n",
    "        train_imgs_list_normalized = []\n",
    "        #prepare training images\n",
    "        for i, img in enumerate(imgs_list):\n",
    "            n_channels = len(img.shape)\n",
    "            \n",
    "           \n",
    "            if (n_channels == 3):\n",
    "                img_norm = img[:,:,0]\n",
    "            else:\n",
    "                img_norm = img\n",
    "            \n",
    "            img_norm = img_norm / 255\n",
    "            train_imgs_list_normalized.append(img_norm)\n",
    "            \n",
    "        # prepare testing images\n",
    "        n_channels = len(test_img.shape)\n",
    "        if (n_channels == 3):\n",
    "            test_img = test_img[:,:,0]\n",
    "        \n",
    "        test_img_normalized = test_img / 255\n",
    "        \n",
    "    # get the mean image for the training samples\n",
    "    global train_mean_img\n",
    "    train_mean_img = np.mean(train_imgs_list_normalized, axis=0)\n",
    "    global auto_encoder_architecture\n",
    "    auto_encoder_architecture = autoencoder(dimensions= data_dimensions)\n",
    "    \n",
    "    # run the graph using the test image\n",
    "    learning_rate = 0.001\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(auto_encoder_architecture['cost'])\n",
    "    global sess\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    # LEarning from training Samples\n",
    "    print('########## Learning Encoders and Decoders ####################')\n",
    "    for epoch_i in range (n_epochs):\n",
    "        np.random.shuffle(train_imgs_list_normalized)\n",
    "        idx = np.random.choice(len(train_imgs_list_normalized), batch_size)\n",
    "        batch_xs = []\n",
    "        for index in range (len(idx)):\n",
    "                batch_xs.append(train_imgs_list_normalized[index])\n",
    "        \n",
    "        pre_processed_batch = np.array([img - train_mean_img for img in batch_xs])\n",
    "        pre_processed_batch = np.reshape(pre_processed_batch, (batch_size,img_w * img_h ))\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={\n",
    "                auto_encoder_architecture['x']: pre_processed_batch\n",
    "            })\n",
    "        current_cost = sess.run(auto_encoder_architecture['cost'], feed_dict={\n",
    "                auto_encoder_architecture['x'] : pre_processed_batch\n",
    "            })\n",
    "        print ('Iteration num: ', epoch_i, ' cost: ', current_cost)\n",
    "        \n",
    "        \n",
    "   # print('########## Decoding Test Image ###################')\n",
    "    \n",
    "    test_img_normalized_mean = test_img_normalized-train_mean_img\n",
    "    test_img_normalized_mean = np.reshape(test_img_normalized, (1,img_w * img_h))\n",
    "    test_reconstructed = sess.run(auto_encoder_architecture['y'], feed_dict={\n",
    "            auto_encoder_architecture['x']: test_img_normalized_mean\n",
    "        })\n",
    "    test_reconstructed = np.reshape(test_reconstructed, (img_w, img_h))\n",
    "    reconstructed_img = test_reconstructed + train_mean_img\n",
    "    #reconstructed_img = test_reconstructed\n",
    "    \n",
    "    \n",
    "    #plots\n",
    "    fig, axs = plt.subplots(3, 1)\n",
    "    axs[0].imshow(test_img, cmap='gray', interpolation='nearest')\n",
    "    axs[1].imshow(train_mean_img, cmap='gray', interpolation='nearest')\n",
    "    axs[2].imshow(reconstructed_img, cmap='gray', interpolation='nearest')\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "    print('Done!')\n",
    "    return reconstructed_img\n",
    "    \n",
    "    \n",
    "def reconstruct_img(test_img_normalized):\n",
    "    test_img_normalized_mean = test_img_normalized-train_mean_img\n",
    "    test_img_normalized_mean1 = 1 - test_img_normalized_mean\n",
    "    test_img_normalized_mean = np.reshape(test_img_normalized_mean1, (1,img_w * img_h))\n",
    "    test_reconstructed = sess.run(auto_encoder_architecture['y'], feed_dict={\n",
    "            auto_encoder_architecture['x']: test_img_normalized_mean\n",
    "        })\n",
    "    test_reconstructed = np.reshape(test_reconstructed, (img_w, img_h))\n",
    "    reconstructed_img = test_reconstructed + train_mean_img\n",
    "    #reconstructed_img = test_reconstructed\n",
    "    \n",
    "    \n",
    "    #plots\n",
    "    fig, axs = plt.subplots(3, 1)\n",
    "    axs[0].imshow(test_img_normalized, cmap='gray', interpolation='nearest')\n",
    "    axs[1].imshow(train_mean_img, cmap='gray', interpolation='nearest')\n",
    "    axs[2].imshow(reconstructed_img, cmap='gray', interpolation='nearest')\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "    print('Done!')\n",
    "    return reconstructed_img\n",
    "    \n",
    "    \n",
    "# basic autoencoder\n",
    "def autoencoder (dimensions=[780, 512, 256, 64]):\n",
    "    # define the netowrk architecture\n",
    "    x = tf.placeholder(tf.float32, [None, dimensions[0]], name='x_input')\n",
    "    current_input = x\n",
    "    \n",
    "    # build the encoder using the train_nromalized datasets\n",
    "    encoded_dataset = []\n",
    "    \n",
    "    for layer_i, n_output in enumerate(dimensions[1:]):\n",
    "        n_input = int(current_input.get_shape()[1])\n",
    "        W = tf.Variable(\n",
    "            tf.random_uniform([n_input, n_output],\n",
    "                            -1.0 / math.sqrt(n_input),\n",
    "                             1.0 / math.sqrt(n_input)))\n",
    "        b = tf.Variable(tf.zeros([n_output]))\n",
    "        \n",
    "        encoded_dataset.append(W)\n",
    "        output = tf.nn.tanh(tf.matmul(current_input, W) + b)\n",
    "        current_input = output\n",
    "        \n",
    "    # latent representation\n",
    "    z = current_input\n",
    "    \n",
    "    #build the decoder \n",
    "    \n",
    "    encoded_dataset.reverse()\n",
    "    dimensions.reverse()\n",
    "    for layer_i, n_output in enumerate(dimensions[1:]):\n",
    "        W = tf.transpose(encoded_dataset[layer_i])\n",
    "        b = tf.Variable(tf.zeros([n_output]))\n",
    "        output = tf.nn.tanh(tf.matmul(current_input, W) + b)\n",
    "        current_input = output\n",
    "        \n",
    "    # Decoded image\n",
    "    y = current_input\n",
    "    \n",
    "    # cost function\n",
    "    cost = tf.reduce_sum(tf.square(y - x))\n",
    "    \n",
    "    \n",
    "    # return output\n",
    "    return {'x': x, 'z': z, 'y': y, 'cost': cost}\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "data = skimage.io.imread_collection('path/your/training/file/*.png')\n",
    "test_sample = skimage.io.imread('path/to/your/test/image')\n",
    "train_samples = data[0:212]\n",
    "train_data = []\n",
    "for i, img in enumerate(datack):\n",
    "    train_data.append(img)\n",
    "\n",
    "plt.imshow(test_sample, cmap='gray')\n",
    "plt.show()\n",
    "train_samples_resized = []\n",
    "for i, img in enumerate(train_data):\n",
    "    img = resize(img, (50,50))\n",
    "    train_samples_resized.append(img)\n",
    "test_sample = resize(test_sample, (50,50))\n",
    "dimensions = [2500, 2300, 2000, 1700, 1400, 1100, 800, 500, 300]\n",
    "\n",
    "res = basic_auto_encoder(train_samples_resized, test_img = test_sample, normalized = False, data_dimensions = dimensions,n_epochs= 10, batch_size=70 )\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
